{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "755b036e",
   "metadata": {},
   "source": [
    "# Employee Attrition Prediction\n",
    "\n",
    "Ye notebook **Sales_Forecasting_Dashboard.ipynb** ki style follow karta hua Employee Attrition Prediction pipeline aur simple Streamlit prediction app provide karta hai.\n",
    "\n",
    "**Usage:** Notebook mein diye gaye `DATA_PATH` ko apne HR dataset (e.g. `HR_Employee_Attrition.csv`) ke path se replace karein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9340abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a0fd3f",
   "metadata": {},
   "source": [
    "## 1) Data Load & Quick Look\n",
    "\n",
    "- Default filename: `HR_Employee_Attrition.csv`\n",
    "- Agar aapka file name alag hai, to `DATA_PATH` change karein.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49305ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset path\n",
    "DATA_PATH = 'HR_Employee_Attrition.csv'\n",
    "\n",
    "# Load\n",
    "if os.path.exists(DATA_PATH):\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print('Dataset loaded:', DATA_PATH)\n",
    "else:\n",
    "    df = pd.DataFrame()\n",
    "    print(f\"File not found: {DATA_PATH}. Please upload the HR dataset in the notebook folder.\")\n",
    "\n",
    "# Quick look\n",
    "if not df.empty:\n",
    "    display(df.head())\n",
    "    print('\\nShape:', df.shape)\n",
    "    print('\\nColumns:', df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1006c9a2",
   "metadata": {},
   "source": [
    "## 2) Exploratory Data Analysis (EDA)\n",
    "- Attrition distribution, key feature plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Attrition distribution\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.countplot(x='Attrition', data=df)\n",
    "    plt.title('Attrition Distribution')\n",
    "    plt.show()\n",
    "\n",
    "    # Numeric summary\n",
    "    display(df.describe(include=[np.number]).T)\n",
    "\n",
    "    # Categorical overview (top categorical columns)\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    print('Categorical columns:', cat_cols)\n",
    "    for c in cat_cols[:6]:\n",
    "        plt.figure(figsize=(6,3))\n",
    "        sns.countplot(y=c, data=df, order=df[c].value_counts().index)\n",
    "        plt.title(c)\n",
    "        plt.show()\n",
    "else:\n",
    "    print('No data to show. Load your dataset first.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230e942e",
   "metadata": {},
   "source": [
    "## 3) Preprocessing & Feature Engineering\n",
    "- Simple pipeline: impute, encode categoricals, scale numerics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97dfc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example preprocessing pipeline\n",
    "if not df.empty:\n",
    "    # target\n",
    "    target = 'Attrition'  # assumes values 'Yes'/'No'\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target].map({'Yes':1, 'No':0})\n",
    "\n",
    "    # identify column types\n",
    "    num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    print('Numerical cols:', num_cols)\n",
    "    print('Categorical cols:', cat_cols)\n",
    "\n",
    "    # Pipelines\n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', num_pipeline, num_cols),\n",
    "        ('cat', cat_pipeline, cat_cols)\n",
    "    ])\n",
    "\n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    print('Train/Test shapes:', X_train.shape, X_test.shape)\n",
    "else:\n",
    "    print('No data to preprocess. Load your dataset first.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0856ae03",
   "metadata": {},
   "source": [
    "## 4) Modeling\n",
    "- Train Logistic Regression, Random Forest, XGBoost\n",
    "- Evaluate with accuracy, precision, recall, ROC-AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ef711",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Example: Random Forest pipeline\n",
    "    rf_pipe = Pipeline([\n",
    "        ('pre', preprocessor),\n",
    "        ('clf', RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "    ])\n",
    "\n",
    "    rf_pipe.fit(X_train, y_train)\n",
    "    y_pred = rf_pipe.predict(X_test)\n",
    "    y_proba = rf_pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "    print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print('Precision:', precision_score(y_test, y_pred))\n",
    "    print('Recall:', recall_score(y_test, y_pred))\n",
    "    print('F1:', f1_score(y_test, y_pred))\n",
    "    print('ROC AUC:', roc_auc_score(y_test, y_proba))\n",
    "\n",
    "    print('\\nClassification Report:\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "    # Save model\n",
    "    model_path = 'attrition_model_rf.pkl'\n",
    "    joblib.dump(rf_pipe, model_path)\n",
    "    print('Saved model to', model_path)\n",
    "else:\n",
    "    print('No data to model. Load your dataset first.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3439b2d5",
   "metadata": {},
   "source": [
    "### Feature importance (approximate)\n",
    "- Since pipeline includes one-hot encoding, extracting importance needs mapping. This cell provides a simple approach for numeric features only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80002ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    try:\n",
    "        # Attempt to get feature importances for RandomForest\n",
    "        pre = rf_pipe.named_steps['pre']\n",
    "        clf = rf_pipe.named_steps['clf']\n",
    "        # This will only work if OneHotEncoder produced feature names (sklearn>=1.0)\n",
    "        try:\n",
    "            num_cols = pre.transformers_[0][2]\n",
    "            cat_cols = pre.transformers_[1][1].named_steps['onehot'].get_feature_names_out(pre.transformers_[1][2])\n",
    "            feature_names = list(num_cols) + list(cat_cols)\n",
    "        except Exception:\n",
    "            feature_names = None\n",
    "\n",
    "        importances = clf.feature_importances_\n",
    "        if feature_names is not None and len(feature_names)==len(importances):\n",
    "            imp_df = pd.DataFrame({'feature':feature_names, 'importance':importances}).sort_values('importance', ascending=False).head(20)\n",
    "            display(imp_df)\n",
    "            plt.figure(figsize=(8,6))\n",
    "            sns.barplot(x='importance', y='feature', data=imp_df)\n",
    "            plt.title('Top feature importances')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print('Could not reliably map feature names to importances. Showing top numeric importances only.')\n",
    "            imp_df = pd.Series(importances[:len(num_cols)], index=num_cols).sort_values(ascending=False)\n",
    "            display(imp_df)\n",
    "    except Exception as e:\n",
    "        print('Error computing importances:', e)\n",
    "else:\n",
    "    print('No data loaded.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4a03c0",
   "metadata": {},
   "source": [
    "## 5) Predict on a single example\n",
    "- Provide a dictionary with employee features and predict attrition probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa4976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example single-prediction (edit the values to match your dataset columns)\n",
    "if not df.empty:\n",
    "    sample = X_test.iloc[0:1].copy()\n",
    "    display(sample)\n",
    "    loaded = joblib.load('attrition_model_rf.pkl')\n",
    "    prob = loaded.predict_proba(sample)[:,1]\n",
    "    pred = loaded.predict(sample)\n",
    "    print('Predicted probability of attrition:', prob[0])\n",
    "    print('Predicted class (1=Attrition):', pred[0])\n",
    "else:\n",
    "    print('No data available.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2238d413",
   "metadata": {},
   "source": [
    "## 6) Optional: Streamlit app (save as `streamlit_app.py` and run `streamlit run streamlit_app.py`)\n",
    "\n",
    "Below code can be copied to a separate `streamlit_app.py` file to provide a simple web UI for predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a447a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit_code = r\"\"\"\n",
    "import streamlit as st\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "st.title('Employee Attrition Predictor')\n",
    "\n",
    "# Load model\n",
    "model = joblib.load('attrition_model_rf.pkl')\n",
    "\n",
    "st.sidebar.header('Employee input')\n",
    "# NOTE: Edit the inputs below to match your dataset features\n",
    "age = st.sidebar.number_input('Age', min_value=18, max_value=80, value=35)\n",
    "monthly_income = st.sidebar.number_input('Monthly Income', min_value=1000, max_value=50000, value=5000)\n",
    "job_role = st.sidebar.selectbox('Job Role', ['Sales Executive','Research Scientist','Laboratory Technician','Manufacturing Director','Healthcare Representative','Manager','Sales Representative','Research Director','Human Resources'])\n",
    "\n",
    "over_time = st.sidebar.selectbox('OverTime', ['Yes','No'])\n",
    "\n",
    "overlay_df = pd.DataFrame({\n",
    "    'Age':[age],\n",
    "    'MonthlyIncome':[monthly_income],\n",
    "    'JobRole':[job_role],\n",
    "    'OverTime':[over_time]\n",
    "})\n",
    "\n",
    "if st.button('Predict'):\n",
    "    proba = model.predict_proba(overlay_df)[:,1]\n",
    "    st.write(f'Probability of attrition: {proba[0]:.3f}')\n",
    "\"\"\"\n",
    "\n",
    "# save to file\n",
    "with open('streamlit_app.py', 'w') as f:\n",
    "    f.write(streamlit_code)\n",
    "print('Saved Streamlit app to streamlit_app.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbc623c",
   "metadata": {},
   "source": [
    "### Notebook & Streamlit file saved\n",
    "- Notebook available as `/mnt/data/Employee_Attrition_Prediction.ipynb`\n",
    "- Streamlit app saved as `/mnt/data/streamlit_app.py`"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
